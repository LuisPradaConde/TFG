{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a23efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import mglearn\n",
    "from sklearnex  import  patch_sklearn \n",
    "patch_sklearn ()\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('dataset_limpio.csv')\n",
    "dataset = dataset.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12dc817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex  import  patch_sklearn \n",
    "patch_sklearn ()\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X = dataset[:int(len(dataset)*0.6)]\n",
    "# reduced_data = PCA(n_components = 0.95).fit_transform(X)\n",
    "# print(reduced_data)\n",
    "\n",
    "# dpos = dataset[dataset.anomaly_scores==1]\n",
    "# dpos2=dpos.iloc[:,0:-2]\n",
    "# dneg = dataset[dataset.anomaly_scores==-1]\n",
    "# dneg2 = dneg.iloc[:,0:-2]\n",
    "\n",
    "\n",
    "\n",
    "def plot_figure(data, labels):\n",
    "    \n",
    "      \n",
    "#     colors = np.array([\"#377eb8\", \"#ff7f00\"])\n",
    "#     plt.scatter(X_pca[:, 0], X_pca[:, 1], s=10, color=colors[(labels + 1) // 2])\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.scatter(data[:,0], data[:,1], c=labels, linewidths= 0.01, edgecolors='k')\n",
    "    plt.savefig(\"OCSVM.pdf\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def bench_marks(name, data, labels, fit_time):\n",
    "    \n",
    "\n",
    "    results = [name, fit_time]\n",
    "\n",
    "    \n",
    "    results += [silhouette_score(data, labels, metric = 'euclidean')]\n",
    "    results += [davies_bouldin_score(data, labels)]\n",
    "    results += [calinski_harabasz_score(data, labels)]\n",
    "    \n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    results += [n_clusters]\n",
    "    \n",
    "    formatter_result = (\n",
    "        \"{:5s}\\t\\t{:.3f}s\\t{:.3f}\\t\\t\\t{:.2f}\\t{:.3f}\\t\\t{:.0f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef36a82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________\n",
      "name\t\t\ttime\t\tsilhouette\tdavies_bouldin\tcalinski_harabasz\tn_clusters\n",
      "\n",
      "[-1  1]\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but SGDOneClassSVM is expecting 34 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m clf \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mSGDOneClassSVM(nu\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m, tol\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-10\u001b[39m ,random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# bench_marks(clf, name=\"linear\")\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m plot_figure(clf)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#SVM\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# svm = OneClassSVM(kernel='rbf',gamma='auto', nu = 0.8)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# bench_marks(svm, name = \"svm linear rbf\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# svm = OneClassSVM(kernel='sigmoid',gamma='scale', nu=0.8)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# bench_marks(svm, name = \"svm sigmoid scale\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m82\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [20], line 34\u001b[0m, in \u001b[0;36mplot_figure\u001b[0;34m(algoritm)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_clusters)\n\u001b[1;32m     33\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m150\u001b[39m), np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m150\u001b[39m))\n\u001b[0;32m---> 34\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43malgoritm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m Z \u001b[38;5;241m=\u001b[39m Z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mcontour(xx, yy, Z, levels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m], linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:2500\u001b[0m, in \u001b[0;36mSGDOneClassSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;124;03m\"\"\"Return labels (1 inlier, -1 outlier) of the samples.\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m \n\u001b[1;32m   2490\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;124;03m        Labels of the samples.\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2500\u001b[0m     y \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m   2501\u001b[0m     y[y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# for consistency with outlier detectors\u001b[39;00m\n\u001b[1;32m   2502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:2466\u001b[0m, in \u001b[0;36mSGDOneClassSVM.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[38;5;124;03m\"\"\"Signed distance to the separating hyperplane.\u001b[39;00m\n\u001b[1;32m   2449\u001b[0m \n\u001b[1;32m   2450\u001b[0m \u001b[38;5;124;03mSigned distance is positive for an inlier and negative for an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2461\u001b[0m \u001b[38;5;124;03m    Decision function values of the samples.\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2464\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2466\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2467\u001b[0m decisions \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset_\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decisions\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 2 features, but SGDOneClassSVM is expecting 34 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import linear_model\n",
    "from sklearnex  import  patch_sklearn \n",
    "patch_sklearn ()\n",
    "\n",
    "random_state = np.random.seed(42)\n",
    "print(82 * \"_\")\n",
    "print(\"name\\t\\t\\ttime\\t\\tsilhouette\\tdavies_bouldin\\tcalinski_harabasz\\tn_clusters\\n\")\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(dataset)\n",
    "pca = PCA(n_components = 0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "clf = linear_model.SGDOneClassSVM(nu= 0.05, tol= 1e-10 ,random_state=random_state)\n",
    "\n",
    "t0 = time()\n",
    "estimator = clf.fit(X_pca)\n",
    "labels= estimator.predict(X_pca)    \n",
    "fit_time = time() - t0\n",
    "\n",
    "\n",
    "bench_marks(name=\"linear\", data = X_pca, labels = labels, fit_time = fit_time)\n",
    "plot_figure(X_pca, labels)\n",
    "\n",
    "print(82 * \"_\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
